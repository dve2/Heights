{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "uVV8-qTSZm4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "krVlltvmZeY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a747570-97ab-4781-e3ea-ff311c911401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-20 18:00:10--  https://ml.gan4x4.ru/msu/students/dubrovin/dataset.zip\n",
            "Resolving ml.gan4x4.ru (ml.gan4x4.ru)... 212.24.105.216\n",
            "Connecting to ml.gan4x4.ru (ml.gan4x4.ru)|212.24.105.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 719304718 (686M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 685.98M  11.2MB/s    in 80s     \n",
            "\n",
            "2024-11-20 18:01:32 (8.60 MB/s) - ‘dataset.zip’ saved [719304718/719304718]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "  inflating: Splitted Dataset/Test/Images/NEPNZ10R.101.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/RNAP_dnfgHOPG2009.008_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/dnfgHOPG2_2009.027_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/fercol.000_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/glus1201w-sm-4-02.0_00015_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/glus120m2w-09-6.0_00005_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/glus601w-1-02.0_00004_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/opcoda0908.022.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/opcoda0908.024.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/opcoda0908.026.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.008.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Test/Labels/NEPNZ10R.101.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/RNAP_dnfgHOPG2009.008_512.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/dnfgHOPG2_2009.027_512.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/fercol.000_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/glus1201w-sm-4-02.0_00015_16Bit.001.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/glus120m2w-09-6.0_00005_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/glus601w-1-02.0_00004_16Bit.001.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/opcoda0908.022.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/opcoda0908.024.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/opcoda0908.026.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.001.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.002.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.004.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.005.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.006.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.007.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.008.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.009.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Masks/!NEPNZ10R.101.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!RNAP_dnfgHOPG2009.008_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!dnfgHOPG2_2009.027_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!fercol.000_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!glus1201w-sm-4-02.0_00015_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!glus120m2w-09-6.0_00005_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!glus601w-1-02.0_00004_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!opcoda0908.022.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!opcoda0908.024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!opcoda0908.026.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.008.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/NEPNZ10R.101.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/RNAP_dnfgHOPG2009.008_512.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/dnfgHOPG2_2009.027_512.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/fercol.000_1024.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/glus1201w-sm-4-02.0_00015_16Bit.001.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/glus120m2w-09-6.0_00005_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/glus601w-1-02.0_00004_16Bit.001.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/opcoda0908.022.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/opcoda0908.024.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/opcoda0908.026.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.001.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.002.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.004.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.005.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.006.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.007.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.008.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.009.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/_glus601w-1-02.0_00004_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_glus1201w-sm-4-02.0_00015_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_opcoda0908.022.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_NEPNZ10R.101.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_opcoda0908.024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_opcoda0908.026.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_RNAP_dnfgHOPG2009.008_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.008.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_dnfgHOPG2_2009.027_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_fercol.000_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_glus120m2w-09-6.0_00005_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.022_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.023_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.028_512.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.031_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.055.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.33.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/M3oda2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070002_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPoda1208.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPoda1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPoda1208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070017.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070021.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00013_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00014_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00015_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00016_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00017_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00020_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00021_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgm1608.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgm1608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgm1608.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgm2_1208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.019.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.020.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.021.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.028.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.029.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.030.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.032.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.049.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda100na1508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda100na1508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda100na1508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1108.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1108.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1108.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1508.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1508.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.026.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapghopgair29070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapghopgair29070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapghopgair29070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapgmair27070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapgmair27070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.023.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.027.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.037.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.039.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.040.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2csoda3108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/3csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/csoda3108.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/csoda3108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2csoda0109.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/5csoda0109.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/5csoda0109.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/3csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/3csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.022_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.023_2048.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.028_512.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.031_2048.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.034.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.035.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.036.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.055.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.33.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/M3oda2208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070002_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPoda1208.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPoda1208.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPoda1208.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070017.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070021.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00013_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00014_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00015_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00016_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00017_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00020_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00021_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.015.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.016.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgm1608.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgm1608.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgm1608.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgm1208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgm2_1208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.015.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.019.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.020.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.021.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.022.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.025.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.028.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.029.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.030.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.031.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.032.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.033.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.034.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.035.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.036.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.049.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda100na1508.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda100na1508.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda100na1508.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1108.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1108.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1108.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1508.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1508.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.018.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.025.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.026.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapghopgair29070000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapghopgair29070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapghopgair29070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapgmair27070003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapgmair27070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.016.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.018.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.022.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.023.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.027.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.031.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.033.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.035.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.037.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.039.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.040.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2csoda0109.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2csoda0109.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2csoda3108.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/csoda3108.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapgmair3008.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/csoda3108.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/csoda0109.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/5csoda0109.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/5csoda0109.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/3csoda0109.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/3csoda0109.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/3csoda0109.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.022_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.023_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.028_512.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.031_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.055.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.33.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!M3oda2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070002_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPoda1208.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPoda1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPoda1208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070017.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00013_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00014_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00015_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00016_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00017_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00020_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00021_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgm1608.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgm1608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgm1608.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgm2_1208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.019.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.020.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.028.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.029.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.030.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.032.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.049.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda100na1508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda100na1508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda100na1508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1108.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1108.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1108.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1508.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1508.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.026.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapghopgair29070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapghopgair29070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapghopgair29070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapgmair27070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapgmair27070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.023.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.027.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.037.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.039.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.040.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.022_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.023_2048.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.028_512.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.031_2048.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.034.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.035.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.036.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.055.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.33.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/M3oda2208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070002_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPoda1208.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPoda1208.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPoda1208.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070017.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070021.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00013_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00014_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00015_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00016_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00017_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00020_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00021_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.015.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.016.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgm1608.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgm1608.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgm1608.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgm1208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgm2_1208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.015.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.019.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.020.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.021.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.022.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.025.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.028.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.029.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.030.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.031.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.032.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.033.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.034.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.035.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.036.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.049.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda100na1508.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda100na1508.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda100na1508.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1108.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1108.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1108.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1508.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1508.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.018.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.025.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.026.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapghopgair29070000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapghopgair29070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapghopgair29070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapgmair27070003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapgmair27070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.016.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.018.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.022.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.023.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.027.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.031.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.033.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.035.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.037.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.039.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.040.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/3csoda0109.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/3csoda0109.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2csoda3108.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2csoda0109.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!csoda3108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!csoda3108.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!5csoda0109.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!5csoda0109.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2csoda0109.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!3csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!3csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!3csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/3csoda0109.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2csoda3108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/csoda3108.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapgmair3008.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/csoda3108.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/csoda0109.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/5csoda0109.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/5csoda0109.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2csoda0109.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_3csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_3csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_5csoda0109.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_5csoda0109.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.022_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.023_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.028_512.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.031_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.33.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_csoda3108.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.055.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_csoda3108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070017.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00013_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00017_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00021_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00020_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00016_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00015_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_M3oda2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00014_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgm1608.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgm1608.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgm1608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgm2_1208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.020.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.019.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.029.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.032.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.028.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.030.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda100na1508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.049.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda100na1508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1108.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda100na1508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1108.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1508.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1508.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1108.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.026.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070002_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapghopgair29070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapghopgair29070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapghopgair29070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapgmair27070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapgmair27070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.023.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.027.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.040.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.037.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPoda1208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPoda1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.039.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPoda1208.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2csoda3108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2csoda0109.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_3csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.003.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm13070003.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm13070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm13070009.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070000.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070004.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070006.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070008.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070010.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/ferfchopg1308_002.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/ferfchopg_2910.026.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00001_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00005_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00010_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00029_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00030_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapg1008.020.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.010.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.014.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.016.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.017.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.023.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.032.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.034.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.038.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.040.txt  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.000.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.001.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.002.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.003.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.004.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.005.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.006.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.007.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.009.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm13070003.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm13070007.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm13070009.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070000.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070001.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070004.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070006.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070007.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070008.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070010.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/ferfchopg1308_002.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/ferfchopg_2910.026.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00001_16Bit.001_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00005_16Bit.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00010_16Bit.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00029_16Bit.001_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00030_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapg1008.020.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.000.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.001.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.005.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.010.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.014.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.016.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.017.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.023.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.032.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.034.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.038.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.040.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm13070003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm13070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm13070009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070008.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!ferfchopg1308_002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!ferfchopg_2910.026.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00001_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00005_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00010_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00029_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00030_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapg1008.020.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.014.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.016.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.017.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.023.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.032.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.034.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.038.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.040.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.000.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.001.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.002.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.003.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.004.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.005.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.006.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.007.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.009.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm13070003.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm13070007.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm13070009.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070000.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070001.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070004.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070006.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070007.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070008.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070010.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/ferfchopg1308_002.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/ferfchopg_2910.026.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00001_16Bit.001_1024.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00005_16Bit.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00010_16Bit.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00029_16Bit.001_1024.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00030_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapg1008.020.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.000.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.001.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.005.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.010.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.014.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.016.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.017.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.023.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.032.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.034.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.038.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.040.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_ferfchopg1308_002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_ferfchopg_2910.026.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00001_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00010_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00030_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00005_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapg1008.020.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00029_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm13070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm13070009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm13070003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070008.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.014.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.017.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.016.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.034.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.038.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.032.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.023.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.040.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.000.txt  \n",
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.26.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (11.0.0)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n",
            "Requirement already satisfied: timm==0.9.7 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.9.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.10.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.11.9)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.4.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "--2024-11-20 18:02:13--  https://github.com/dve2/Heights/blob/main/weights/epoch%3D931-step%3D11184.ckpt\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘epoch=931-step=11184.ckpt.1’\n",
            "\n",
            "epoch=931-step=1118     [ <=>                ] 282.82K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-20 18:02:13 (1.94 MB/s) - ‘epoch=931-step=11184.ckpt.1’ saved [289608]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://ml.gan4x4.ru/msu/students/dubrovin/dataset.zip\n",
        "#!wget https://github.com/dve2/Heights/tree/main/tests/data\n",
        "!unzip dataset.zip\n",
        "!pip install segmentation-models-pytorch lightning torchmetrics\n",
        "!wget https://github.com/dve2/Heights/blob/main/weights/epoch%3D931-step%3D11184.ckpt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import nan\n",
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import warnings\n",
        "import ast\n",
        "#from torchvision import tv_tensors\n",
        "import pickle\n",
        "import torchvision.transforms.functional as F\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "def load_cache(filename = \"cachedm.pickle\"):\n",
        "      if os.path.isfile(filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "           cache =  pickle.load(f)\n",
        "        print(f\"Loaded cache from {filename}\")\n",
        "        return cache\n",
        "      return None\n",
        "cache = load_cache()\n",
        "\n",
        "class CustomDataset2chdm(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, target_transform = None, exclude = [], cache = None):\n",
        "      images = glob(f\"{root_dir}{os.sep}Images{os.sep}*\")\n",
        "      labels = glob(f\"{root_dir}{os.sep}Masks{os.sep}_*\") # read only continuous heigths\n",
        "      # extract id from paths\n",
        "      im = set(map(lambda x: Path(x).stem,images))\n",
        "      lab = set(map(lambda x: Path(x).stem[1:],labels))\n",
        "      img_without_masks = im - lab\n",
        "      if len(img_without_masks) > 0:\n",
        "        warn_text = f\"Found images without masks {','.join(img_without_masks)}\"\n",
        "        warnings.warn(warn_text)\n",
        "      self.items =  (list((im & lab) - set(exclude)))\n",
        "      self.items.sort()\n",
        "      self.root_dir = root_dir\n",
        "      self.transform = transform\n",
        "      self.target_transform = target_transform\n",
        "      self.max_height = 100\n",
        "      if cache == None:\n",
        "          self.cache = {}\n",
        "      else:\n",
        "        self.cache = cache\n",
        "\n",
        "      #self.load_cache()\n",
        "      #self.scales = self.get_all_scales()\n",
        "\n",
        "    def get_all_scales(self):\n",
        "        scales = []\n",
        "        for name in self.items:\n",
        "            path = self.get_im_path(name)\n",
        "            image, real_w = self.txt2pil(path)\n",
        "            scales.append(self.get_scale(image, real_w))\n",
        "        return np.array(scales)\n",
        "\n",
        "    def get_scale(self, img, real_w):\n",
        "      return  real_w / img.shape[1]   #  micron per pixel; \"[0]\" changed to \"[1]\"\n",
        "\n",
        "    def get_im_path(self,name):\n",
        "      path = f\"{self.root_dir}{os.sep}Images{os.sep}{name}.txt\"\n",
        "      return path\n",
        "\n",
        "    def get_mask_path(self,name):\n",
        "      path = f\"{self.root_dir}{os.sep}Masks{os.sep}_{name}.txt\"\n",
        "      return path\n",
        "\n",
        "    def save_cache(self,filename = \"cache.pickle\"):\n",
        "      with open(filename, 'wb') as f:\n",
        "        pickle.dump(self.cache, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def load_cache(self,filename = \"cache.pickle\"):\n",
        "      if os.path.isfile(filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "          self.cache =  pickle.load(f)\n",
        "        print(f\"Loaded cache from {filename}\")\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.items)\n",
        "\n",
        "    def line2tensor(self,line):\n",
        "        txt = line.strip()\n",
        "        parts = txt.split(\"\\t\")\n",
        "        parts = list(filter(len,parts)) #remove empty\n",
        "        if len(parts) <= 2:\n",
        "          return None\n",
        "        numbers = list(map(float, parts))\n",
        "        t = torch.tensor(numbers)\n",
        "        return t\n",
        "\n",
        "\n",
        "    def txt2pil(self, filename):\n",
        "      if filename in self.cache and \"image\" in self.cache[filename]:\n",
        "        return self.cache[filename][\"image\"].copy(), self.cache[filename][\"real_w\"]\n",
        "\n",
        "      # convert list of relative heights to image\n",
        "      with open(filename, encoding='unicode_escape') as file:\n",
        "        x_line = file.readline() # X\n",
        "        x = self.line2tensor(x_line[6:]) # bypass X,nm \"8:\" was replaced by \"5:\"\n",
        "        real_w = (x.max()-x.min()).item() #let it be in microns\n",
        "        units = x_line[3:5]\n",
        "        if units == \"A°\":\n",
        "          real_w = real_w/10000\n",
        "        if units == \"nm\":\n",
        "          real_w = real_w/1000\n",
        "        line = file.readline() # Y, Z skip it\n",
        "        lines = []\n",
        "        for line in file:\n",
        "          if line != '\\n':  #to exclude the last line\n",
        "            pos = line.index('\\t')#position of the first tabulation\n",
        "            line2 = line[(pos + 2):]#exclude Y-coordinate and 2 tabulations after it\n",
        "            t = self.line2tensor(line2)\n",
        "            if t is not None:\n",
        "              lines.append(t)\n",
        "        t = torch.stack(lines)\n",
        "        # Shift to zero\n",
        "        # Because all heights just a difference between current and randomly sampled point\n",
        "        t = t - t.min()\n",
        "        t = t.numpy()\n",
        "        self.cache[filename]= {\"image\": t, \"real_w\" : real_w}\n",
        "      return t, real_w\n",
        "\n",
        "\n",
        "    def load_heights(self, path):\n",
        "      \"\"\"\n",
        "        get heights of some points marked by human\n",
        "      \"\"\"\n",
        "      df = pd.read_excel(path)\n",
        "      return self.fix_format(df)\n",
        "\n",
        "\n",
        "    def get_height_map(self, path):\n",
        "      if not (path in self.cache and \"mask\" in self.cache[path]):\n",
        "          with open(path, 'r') as file:\n",
        "            content = file.read()\n",
        "          x = ast.literal_eval(content)\n",
        "          x = np.array(x)\n",
        "          self.cache[path] = { \"mask\" : x }\n",
        "      return self.cache[path][\"mask\"].copy()\n",
        "      #return x\n",
        "\n",
        "\n",
        "    def __getitem__(self,n):\n",
        "      \"\"\"\n",
        "        img - data(raw heights) from microscope\n",
        "        masks - continious globules height map\n",
        "\n",
        "        real_w - width of the image in microns\n",
        "      \"\"\"\n",
        "      name = self.items[n]\n",
        "      img = self.get_im_path(name)\n",
        "      mask = self.get_mask_path(name)\n",
        "\n",
        "      image, real_w = self.txt2pil(img)\n",
        "      mask = self.get_height_map(mask)\n",
        "\n",
        "      #image, orig_size, scale_factor = self.rescale(image,real_w)\n",
        "      #mask, _, _ = self.rescale(mask,real_w)\n",
        "      scale_factor = 0\n",
        "\n",
        "      if self.transform:\n",
        "        output = self.transform(image=image, mask=mask)\n",
        "        image = output['image']\n",
        "        mask = output['mask'] # here mask is cropped but not normalized\n",
        "        # TODO resize to one scale\n",
        "        if self.target_transform:\n",
        "          mask = self.target_transform(mask)\n",
        "      meta = {\"w\": real_w, 'name' : name, \"scale_factor\": scale_factor} # , centers: [[x1,y1],[x2,y2]]\n",
        "      binary_mask = torch.where(mask != 0, 1, 0)\n",
        "      mask2 = torch.unsqueeze(binary_mask, 0)\n",
        "      im_mask = torch.cat((image, mask2), 0) #creates two channel tensor, where 1 channel is image, 2nd channel is mask\n",
        "      return im_mask, image, mask, meta\n",
        "\n",
        "    def rescale(self,img, real_w):\n",
        "      resize_coeff = 1\n",
        "      h,w = img.shape[:2]\n",
        "      original_size = (h,w)\n",
        "      #most_popular_scale = mode(self.scales)\n",
        "      most_popular_scale = 0.00389862060546875\n",
        "      scale = self.get_scale(img,real_w)\n",
        "      if most_popular_scale != scale:\n",
        "        resize_coeff = most_popular_scale/scale\n",
        "      new_size = tuple((np.array(original_size) / resize_coeff).astype(int).tolist()) # '*' changed to '/'\n",
        "      img = cv2.resize(img, new_size)\n",
        "      return img, original_size, resize_coeff"
      ],
      "metadata": {
        "id": "je33EylelYP7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTTJMMtwlbLk",
        "outputId": "1083c98b-d5ee-4b1d-ad02-8e6329281128"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean, std = [8.489298], [9.06547]\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean, std),\n",
        "        A.RandomCrop(192, 192),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean, std),\n",
        "        A.CenterCrop(192, 192),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "class NormalizeNonZero(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, x):\n",
        "        mask = x == 0\n",
        "        x -= self.mean\n",
        "        x /= self.std\n",
        "        x[mask] = 0\n",
        "        return x.to(torch.float32)\n",
        "\n",
        "    def denorm(self,x):\n",
        "        mask = x == 0\n",
        "        x *=  self.std\n",
        "        x += self.mean\n",
        "        x[mask] = 0\n",
        "        return x\n",
        "\n",
        "dot_target_mean, dot_target_std = 3.016509424749255, 2.452459479074767\n",
        "nnz = NormalizeNonZero(dot_target_mean, dot_target_std)\n",
        "\n",
        "target_transform = T.Compose([nnz])"
      ],
      "metadata": {
        "id": "jxmy2qxNllBM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from math import nan\n",
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import warnings\n",
        "import ast\n",
        "#from torchvision import tv_tensors\n",
        "import pickle\n",
        "import torchvision.transforms.functional as F\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "vKxpyqYLlnK7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ds_train = CustomDataset2chdm(\"Splitted Dataset/Train\", transform  = train_transforms, target_transform = target_transform, cache = cache)\n",
        "loader_train = DataLoader(ds_train, batch_size=16, shuffle=True, num_workers=2)\n",
        "#ds_train = CustomDataset(\"Splitted Dataset/Train\")\n",
        "\n",
        "ds_val = CustomDataset2chdm(\"Splitted Dataset/Val\", transform  = val_transforms, target_transform=target_transform, cache = cache)\n",
        "loader_val = DataLoader(ds_val, batch_size=4, shuffle=False, num_workers=2)\n",
        "#ds_val = CustomDataset(\"Splitted Dataset/Val\")\n",
        "'''\n",
        "\n",
        "ds_test = CustomDataset2chdm(\"Splitted Dataset/Test\", transform  = val_transforms, target_transform=target_transform, cache = cache)\n",
        "loader_test = DataLoader(ds_test, batch_size=4, shuffle=False, num_workers=2)\n",
        "#ds_test = CustomDataset(\"Splitted Dataset/Test\")"
      ],
      "metadata": {
        "id": "Tu6dh7I-plex"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import MeanSquaredError\n",
        "from typing import Any, Optional, Sequence, Union\n",
        "from torch import Tensor\n",
        "\n",
        "class ZeroAwareMSE(MeanSquaredError):\n",
        "    def update(self, preds: Tensor, target: Tensor) -> None:\n",
        "        target_sum = torch.sum(target).item()\n",
        "        if target_sum == 0:#change preds and targets in such a way that the result would be zero tensor (not works directly)\n",
        "            preds = preds - preds + 1\n",
        "            target = target + 1\n",
        "        mask = target != 0\n",
        "        return super().update(preds[mask],target[mask])\n"
      ],
      "metadata": {
        "id": "67bQWP-Rlq3r"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MSELoss_mask(pred, target): #MSE loss calculated only inside the masks (which are contained in the targets)\n",
        "  mse_loss = MSELoss(reduction='sum')  #calculates sum of the squared errors (without division by n)\n",
        "  loss = mse_loss(pred, target) #calculates sum of the squared errors (without division by n)\n",
        "  target_binary = torch.where(target != 0, 1, 0) #writing 1 in each unmasked pixel and 0 in each masked pixel (for calculation the number of unmasked pixels)\n",
        "  n_ummasked_pxls = target_binary.sum()#.item() #calculating the number of unmasked pixels\n",
        "  if n_ummasked_pxls == 0:\n",
        "    return 0\n",
        "\n",
        "  return loss/n_ummasked_pxls\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomLoss, self).__init__()\n",
        "\n",
        "  def forward(self, pred, target):\n",
        "    return MSELoss_mask(pred, target)"
      ],
      "metadata": {
        "id": "ML01J5fFlrWV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning as L\n",
        "from torchmetrics import MeanSquaredError\n",
        "from torch.nn import MSELoss\n",
        "import torch\n",
        "\n",
        "class Lit(L.LightningModule):\n",
        "    def __init__(self, model, lr=0.0025):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "        self.criterion = CustomLoss()\n",
        "        self.save_hyperparameters()\n",
        "        self.metric_train = ZeroAwareMSE()\n",
        "        self.metric_train_dn = ZeroAwareMSE()\n",
        "        self.metric_val = ZeroAwareMSE()\n",
        "        self.metric_val_dn = ZeroAwareMSE()\n",
        "        self.metric_test = ZeroAwareMSE()\n",
        "        self.metric_test_dn = ZeroAwareMSE()  #??\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        _, imgs, masks, meta = batch\n",
        "        predicted_masks = self.get_prediction(batch)\n",
        "        #print(predicted_masks, masks)\n",
        "        loss = self.criterion(predicted_masks, masks)\n",
        "        #loss_dn = self.criterion(nnz.denorm(predicted_masks), nnz.denorm(masks))\n",
        "        self.log(\"Loss/\", loss.item(), prog_bar=False)\n",
        "        #self.log(\"Loss_dn/\", loss_dn.item(), prog_bar=False)\n",
        "        self.metric_train.update(predicted_masks, masks)\n",
        "        #self.metric_train_dn.update(nnz.denorm(predicted_masks), nnz.denorm(masks))\n",
        "        return loss\n",
        "\n",
        "    def get_prediction(self,batch):\n",
        "        im_masks, imgs, masks, meta = batch\n",
        "        predicted_masks = self.model(im_masks).squeeze(1)\n",
        "        predicted_masks = self.postprocess(predicted_masks, masks)\n",
        "        return predicted_masks\n",
        "\n",
        "    def postprocess(self, pred, mask):\n",
        "        pred = pred.squeeze(1)\n",
        "        pred[mask == 0] = 0\n",
        "        return pred\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, imgs, masks, meta = batch\n",
        "        predicted_masks = self.get_prediction(batch)\n",
        "        self.metric_val.update(predicted_masks, masks)\n",
        "        self.metric_val_dn.update(nnz.denorm(predicted_masks), nnz.denorm(masks))\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"MSE/val\", self.metric_val.compute(), prog_bar=True)\n",
        "        self.log(\"MSE/val_dn\", self.metric_val_dn.compute(), prog_bar=True)\n",
        "        self.metric_val.reset()\n",
        "        self.metric_val_dn.reset()\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"MSE/train\", self.metric_train.compute())\n",
        "        #self.log(\"MSE_dn/train\", self.metric_train_dn.compute())\n",
        "        self.metric_train.reset()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        im_masks, imgs, masks, _ = batch\n",
        "        predicted_masks = self.get_prediction(batch)\n",
        "        self.log(\"MSE/test\", self.metric_test.compute(), prog_bar=True)\n",
        "        self.metric_test.update(predicted_masks, masks)\n",
        "        self.metric_test_dn.update(nnz.denorm(predicted_masks), nnz.denorm(masks))#??\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log(\"MSE/test\", self.metric_test.compute(), prog_bar=True)\n",
        "        self.log(\"MSE/test_dn\", self.metric_test_dn.compute(), prog_bar=True)\n",
        "        self.metric_test.reset()\n",
        "        self.metric_test_dn.reset()"
      ],
      "metadata": {
        "id": "w2ivf6U_lwIT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "smp_unet = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b0\",  # choose encoder\n",
        "    encoder_weights=None,  # use `imagenet` pre-trained weights for encoder initialization\n",
        "    in_channels=2,  # model input channels 3 for RGB\n",
        "    classes=1,  # model output channels (number of classes in mask)\n",
        ")"
      ],
      "metadata": {
        "id": "gQGnHolflzfr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='MSE/val',\n",
        "    #monitor='MSE/train',\n",
        "    dirpath='lightning_logs',\n",
        "    #filename='sample-mnist-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=5,\n",
        "    mode='min',\n",
        "    #every_n_epochs=10\n",
        ")\n",
        "\n",
        "lit_model = Lit(smp_unet)\n",
        "\n",
        "#To continue from checkpoint:\n",
        "#lit_model = Lit.load_from_checkpoint(\"/home/jupyter/datasphere/project/lightning_logs/epoch=361-step=4344.ckpt\")\n",
        "#model = lit_model.model\n",
        "#model.train()\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name=\"SMPUnet\")\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=5,\n",
        "    logger=logger,\n",
        "    log_every_n_steps=5,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")  # def on_validation_epoch_start(self):\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBoOEfP5pzK5",
        "outputId": "b954a52d-cef4-46c6-dd2c-0d85f26eab57"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model1 = Lit.load_from_checkpoint('epoch=931-step=11184.ckpt')\n",
        "model = lit_model1.model\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "_81mBlxTl1Or",
        "outputId": "45b8f4b2-cf8f-47e8-8cc1-503c855632b6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "invalid load key, '\\x0a'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-81801e6d13c4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlit_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch=931-step=11184.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlit_model1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/model_helpers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m                     \u001b[0;34m\" Please call it on the class type and make sure the return value is used.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 )\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m         \"\"\"\n\u001b[0;32m-> 1582\u001b[0;31m         loaded = _load_from_checkpoint(\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/pytorch/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_location\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_default_map_location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# convert legacy checkpoints to the new format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/cloud_io.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         return torch.load(\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1385\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1626\u001b[0m         )\n\u001b[1;32m   1627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x0a'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrMZD_apl53U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "def get_dotted_cropped_test_mask(flnm):\n",
        "    root_dir = \"Splitted Dataset/Test\"\n",
        "    path = f\"{root_dir}{os.sep}Masks{os.sep}_{flnm}.txt\"\n",
        "    with open(path, 'r') as file:\n",
        "        content = file.read()\n",
        "        x = ast.literal_eval(content)\n",
        "        x = np.array(x)\n",
        "    return x\n",
        "\n",
        "def get_dotted_cropped_val_mask(flnm):\n",
        "    root_dir = \"Splitted Dataset/Val\"\n",
        "    path = f\"{root_dir}{os.sep}Masks{os.sep}_{flnm}.txt\"\n",
        "    with open(path, 'r') as file:\n",
        "        content = file.read()\n",
        "        x = ast.literal_eval(content)\n",
        "        x = np.array(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_-JfpgLumOPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "dot_mse = []\n",
        "for item in ds_test:\n",
        "    im_mask, img, mask, meta = item\n",
        "    pred = model(im_mask.unsqueeze(0))\n",
        "    d_pred = nnz.denorm(pred)\n",
        "    d_pred = d_pred.squeeze(0).squeeze(0)\n",
        "    d_pred[mask ==0] =0\n",
        "    d_mask = nnz.denorm(mask)\n",
        "    flnm = meta['name']\n",
        "    dotted_mask = get_dotted_cropped_test_mask(flnm)\n",
        "    t = torch.from_numpy(dotted_mask)\n",
        "    center_crop = [A.CenterCrop(192, 192)(image = t)]\n",
        "    ten_cr = center_crop[0]['image']\n",
        "    zmse = ZeroAwareMSE()\n",
        "    dot_mse.append(zmse(d_pred,ten_cr).item())\n",
        "print(\"Mean dotted MSE on test =\", np.mean(dot_mse))\n",
        "'''"
      ],
      "metadata": {
        "id": "huZp2g3OmQZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_masks, img, mask, meta = ds_test[0]  #Designate here the image for inference\n",
        "pred = smp_unet(im_masks.unsqueeze(0))\n",
        "d_pred = nnz.denorm(pred)\n",
        "d_pred = d_pred.squeeze(0).squeeze(0)\n",
        "d_pred[mask ==0] =0\n",
        "d_mask = nnz.denorm(mask)"
      ],
      "metadata": {
        "id": "jr5FvqOssofh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(9,2))\n",
        "ttt1 = img.squeeze(0).detach().cpu().numpy()\n",
        "plt.subplot(1,4,1)\n",
        "plt.title('Initial image')\n",
        "ttt1 = plt.imshow(ttt1)\n",
        "\n",
        "ttt3 = d_pred.squeeze(0).detach().cpu().numpy()\n",
        "plt.subplot(1,4,2)\n",
        "plt.title('Model prediction')\n",
        "ttt3 = plt.imshow(ttt3)"
      ],
      "metadata": {
        "id": "xdkQnrdotIzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flnm = meta['name']\n",
        "dotted_mask = get_dotted_cropped_test_mask(flnm)\n",
        "t = torch.from_numpy(dotted_mask)\n",
        "center_crop = [A.CenterCrop(192, 192)(image = t)]\n",
        "ten_cr = center_crop[0]['image']\n",
        "zmse = ZeroAwareMSE()\n",
        "aaaa=zmse(d_pred,ten_cr)\n",
        "print('MSE = ', aaaa.item())"
      ],
      "metadata": {
        "id": "FiHSEsL3tLWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2wCCseNtLzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYC0Z2jhtL6B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}