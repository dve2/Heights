{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "uVV8-qTSZm4o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "krVlltvmZeY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e1d8c4-cde0-437e-82db-dab9b5c6d394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-20 11:46:34--  https://downloader.disk.yandex.ru/zip/a6bc074bd0b2a509ef57c40680633b7335d6528dc3ff4bf0fa516a813e1676b5/69984a12/bkR0RFB3emxKalVXQzMzSUROK3RYbEpxMGpXTFVnS1ZZMFIvQWg1bzFPS0dhTWxKWitCdFl0QVlYbzZMZHNDR0VrSTBlMGl0L1A1M0pqQktkcmpGdWc9PTo=?uid=0&filename=Weights.zip&disposition=attachment&hash=nDtDPwzlJjUWC33IDN%2BtXlJq0jWLUgKVY0R/Ah5o1OKGaMlJZ%2BBtYtAYXo6LdsCGEkI0e0it/P53JjBKdrjFug%3D%3D%3A&limit=0&owner_uid=1130000061557524&force_public=1&tknv=v3\n",
            "Resolving downloader.disk.yandex.ru (downloader.disk.yandex.ru)... 77.88.21.127, 2a02:6b8::2:127\n",
            "Connecting to downloader.disk.yandex.ru (downloader.disk.yandex.ru)|77.88.21.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘weights.zip’\n",
            "\n",
            "weights.zip             [           <=>      ]  63.84M  11.8MB/s    in 4.5s    \n",
            "\n",
            "2026-02-20 11:46:39 (14.1 MB/s) - ‘weights.zip’ saved [66939240]\n",
            "\n",
            "Archive:  weights.zip\n",
            "  inflating: Weights/epoch=4993-step=59928.ckpt  \n",
            "--2026-02-20 11:46:41--  https://ml.gan4x4.ru/msu/students/dubrovin/dataset.zip\n",
            "Resolving ml.gan4x4.ru (ml.gan4x4.ru)... 212.24.105.216\n",
            "Connecting to ml.gan4x4.ru (ml.gan4x4.ru)|212.24.105.216|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 719304718 (686M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>] 685.98M  11.4MB/s    in 60s     \n",
            "\n",
            "2026-02-20 11:47:42 (11.4 MB/s) - ‘dataset.zip’ saved [719304718/719304718]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "  inflating: Splitted Dataset/Test/Images/NEPNZ10R.101.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/RNAP_dnfgHOPG2009.008_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/dnfgHOPG2_2009.027_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/fercol.000_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/glus1201w-sm-4-02.0_00015_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/glus120m2w-09-6.0_00005_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/glus601w-1-02.0_00004_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/opcoda0908.022.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/opcoda0908.024.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/opcoda0908.026.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.008.txt  \n",
            "  inflating: Splitted Dataset/Test/Images/psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Test/Labels/NEPNZ10R.101.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/RNAP_dnfgHOPG2009.008_512.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/dnfgHOPG2_2009.027_512.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/fercol.000_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/glus1201w-sm-4-02.0_00015_16Bit.001.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/glus120m2w-09-6.0_00005_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/glus601w-1-02.0_00004_16Bit.001.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/opcoda0908.022.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/opcoda0908.024.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/opcoda0908.026.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.001.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.002.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.004.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.005.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.006.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.007.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.008.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Labels/psfopcgmair2508.009.xlsx  \n",
            "  inflating: Splitted Dataset/Test/Masks/!NEPNZ10R.101.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!RNAP_dnfgHOPG2009.008_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!dnfgHOPG2_2009.027_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!fercol.000_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!glus1201w-sm-4-02.0_00015_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!glus120m2w-09-6.0_00005_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!glus601w-1-02.0_00004_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!opcoda0908.022.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!opcoda0908.024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!opcoda0908.026.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.008.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/!psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/NEPNZ10R.101.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/RNAP_dnfgHOPG2009.008_512.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/dnfgHOPG2_2009.027_512.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/fercol.000_1024.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/glus1201w-sm-4-02.0_00015_16Bit.001.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/glus120m2w-09-6.0_00005_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/glus601w-1-02.0_00004_16Bit.001.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/opcoda0908.022.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/opcoda0908.024.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/opcoda0908.026.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.001.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.002.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.004.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.005.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.006.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.007.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.008.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/psfopcgmair2508.009.json  \n",
            "  inflating: Splitted Dataset/Test/Masks/_glus601w-1-02.0_00004_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_glus1201w-sm-4-02.0_00015_16Bit.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_opcoda0908.022.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_NEPNZ10R.101.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_opcoda0908.024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_opcoda0908.026.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_RNAP_dnfgHOPG2009.008_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_psfopcgmair2508.008.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_dnfgHOPG2_2009.027_512.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_fercol.000_1024.txt  \n",
            "  inflating: Splitted Dataset/Test/Masks/_glus120m2w-09-6.0_00005_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.022_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.023_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.028_512.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.031_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.055.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2017.03.30 CP MPO.33.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/M3oda2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070002_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP12070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAP_GM0108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPgm1208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPoda1208.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPoda1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPoda1208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/RNAPodag18070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070017.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/cx25070021.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00013_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00014_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00015_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00016_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00017_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00020_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/glut6m1w-2-1.0_00021_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opc100naoda1808.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgm1608.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgm1608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgm1608.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/m3opcgmair2508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgm2_1208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2308.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcgmair2_2308.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.019.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.020.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.021.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.028.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.029.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.030.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.032.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcm3_2208.049.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda100na1508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda100na1508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda100na1508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1108.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1108.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1108.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1508.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda1508.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/opcoda2608.026.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/psf_odag19070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapg100Na1008.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapghopgair29070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapghopgair29070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapghopgair29070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapgmair27070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapgmair27070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.023.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.027.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.037.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.039.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapoda0208.040.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2csoda3108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/3csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/csoda3108.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/csoda3108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/rnapgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/2csoda0109.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/5csoda0109.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/scgmair3008.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/5csoda0109.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/4csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/3csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Images/3csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.022_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.023_2048.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.028_512.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.031_2048.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.034.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.035.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.036.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.055.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2017.03.30 CP MPO.33.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/M3oda2208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070002_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP12070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAP_GM0108.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPgm1208.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPoda1208.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPoda1208.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPoda1208.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/RNAPodag18070009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070017.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/cx25070021.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00013_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00014_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00015_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00016_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00017_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00020_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/glut6m1w-2-1.0_00021_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.015.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opc100naoda1808.016.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgm1608.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgm1608.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgm1608.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/m3opcgmair2508.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgm1208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgm2_1208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2308.015.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcgmair2_2308.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.019.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.020.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.021.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.022.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.025.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.028.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.029.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.030.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.031.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.032.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.033.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.034.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.035.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.036.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcm3_2208.049.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda100na1508.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda100na1508.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda100na1508.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1108.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1108.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1108.013.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1508.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda1508.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.018.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.025.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/opcoda2608.026.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/psf_odag19070010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapg100Na1008.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapghopgair29070000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapghopgair29070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapghopgair29070006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapgmair27070003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapgmair27070004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.010.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.014.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.016.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.018.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.022.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.023.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.024.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.027.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.031.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.033.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.035.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.037.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.039.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapoda0208.040.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2csoda0109.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2csoda0109.005.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/2csoda3108.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.007.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/scgmair3008.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/csoda3108.012.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/rnapgmair3008.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/csoda3108.008.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/csoda0109.004.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/5csoda0109.011.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/5csoda0109.009.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.006.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/4csoda0109.000.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/3csoda0109.003.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/3csoda0109.001.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Labels/3csoda0109.002.xlsx  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.022_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.023_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.028_512.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.031_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.055.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2017.03.30 CP MPO.33.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!M3oda2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070002_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP12070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAP_GM0108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPgm1208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPoda1208.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPoda1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPoda1208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!RNAPodag18070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070017.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!cx25070021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00013_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00014_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00015_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00016_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00017_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00020_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!glut6m1w-2-1.0_00021_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opc100naoda1808.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgm1608.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgm1608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgm1608.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!m3opcgmair2508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgm2_1208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2308.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcgmair2_2308.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.019.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.020.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.028.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.029.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.030.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.032.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcm3_2208.049.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda100na1508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda100na1508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda100na1508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1108.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1108.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1108.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1508.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda1508.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!opcoda2608.026.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!psf_odag19070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapg100Na1008.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapghopgair29070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapghopgair29070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapghopgair29070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapgmair27070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapgmair27070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.023.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.027.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.037.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.039.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapoda0208.040.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.022_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.023_2048.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.028_512.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.031_2048.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.034.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.035.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.036.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.055.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/2017.03.30 CP MPO.33.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/M3oda2208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070002_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP12070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAP_GM0108.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPgm1208.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPoda1208.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPoda1208.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPoda1208.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/RNAPodag18070009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070017.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/cx25070021.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00013_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00014_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00015_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00016_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00017_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00020_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/glut6m1w-2-1.0_00021_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.015.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opc100naoda1808.016.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgm1608.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgm1608.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgm1608.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/m3opcgmair2508.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgm1208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgm2_1208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2308.015.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcgmair2_2308.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.019.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.020.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.021.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.022.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.025.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.028.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.029.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.030.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.031.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.032.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.033.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.034.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.035.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.036.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcm3_2208.049.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda100na1508.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda100na1508.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda100na1508.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1108.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1108.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1108.013.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1508.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda1508.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.018.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.025.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/opcoda2608.026.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/psf_odag19070010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapg100Na1008.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapghopgair29070000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapghopgair29070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapghopgair29070006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapgmair27070003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapgmair27070004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.010.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.014.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.016.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.018.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.022.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.023.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.024.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.027.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.031.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.033.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.035.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.037.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.039.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapoda0208.040.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/3csoda0109.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/3csoda0109.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2csoda3108.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2csoda0109.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!scgmair3008.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!rnapgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!csoda3108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!csoda3108.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!5csoda0109.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!5csoda0109.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!4csoda0109.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/2csoda0109.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!3csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!3csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!3csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/3csoda0109.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2csoda3108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/csoda3108.012.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.007.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.005.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/rnapgmair3008.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/csoda3108.008.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/csoda0109.004.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/5csoda0109.011.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/5csoda0109.009.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.003.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.002.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.001.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/4csoda0109.000.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/scgmair3008.006.json  \n",
            "  inflating: Splitted Dataset/Train/Masks/!2csoda0109.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_3csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_3csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_4csoda0109.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_5csoda0109.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_5csoda0109.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.022_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.023_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.028_512.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.031_2048.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.33.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_csoda3108.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2017.03.30 CP MPO.055.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_csoda3108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_cx25070017.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00013_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00017_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00021_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00020_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00016_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00015_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_M3oda2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_glut6m1w-2-1.0_00014_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgm1608.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgm1608.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opc100naoda1808.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgm1608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgm2_1208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_m3opcgmair2508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2_2308.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.015.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcgmair2308.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.020.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.021.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.019.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.029.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.032.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.028.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.034.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.030.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda100na1508.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.049.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcm3_2208.036.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda100na1508.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1108.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda100na1508.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1108.013.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1508.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1508.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda1108.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.026.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.025.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_opcoda2608.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_psf_odag19070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP_GM0108.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070002_1024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAP12070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapg100Na1008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapghopgair29070000.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapghopgair29070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapghopgair29070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapgmair27070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.011.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapgmair27070004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPgm1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.010.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.016.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.018.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.022.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.023.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.027.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.014.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.031.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.024.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.033.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.040.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.037.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.035.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPoda1208.012.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPoda1208.009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070001.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_rnapoda0208.039.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPoda1208.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070009.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070008.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.003.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_RNAPodag18070007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.006.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2csoda3108.002.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_scgmair3008.007.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2csoda0109.004.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_2csoda0109.005.txt  \n",
            "  inflating: Splitted Dataset/Train/Masks/_3csoda0109.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.003.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/2psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm13070003.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm13070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm13070009.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070000.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070004.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070006.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070008.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/RNAPgm14070010.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/ferfchopg1308_002.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/ferfchopg_2910.026.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00001_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00005_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00010_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00029_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/glu0-26.0_00030_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapg1008.020.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.010.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.014.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.016.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.017.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.023.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.032.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.034.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.038.txt  \n",
            "  inflating: Splitted Dataset/Val/Images/rnapstac0308.040.txt  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.000.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.001.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.002.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.003.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.004.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.005.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.006.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.007.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/2psfopcgmair2508.009.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm13070003.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm13070007.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm13070009.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070000.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070001.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070004.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070006.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070007.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070008.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/RNAPgm14070010.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/ferfchopg1308_002.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/ferfchopg_2910.026.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00001_16Bit.001_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00005_16Bit.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00010_16Bit.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00029_16Bit.001_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/glu0-26.0_00030_16Bit_1024.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapg1008.020.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.000.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.001.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.005.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.010.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.014.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.016.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.017.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.023.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.032.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.034.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.038.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Labels/rnapstac0308.040.xlsx  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!2psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm13070003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm13070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm13070009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070008.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!RNAPgm14070010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!ferfchopg1308_002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!ferfchopg_2910.026.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00001_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00005_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00010_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00029_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!glu0-26.0_00030_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapg1008.020.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.014.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.016.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.017.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.023.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.032.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.034.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.038.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/!rnapstac0308.040.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.000.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.001.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.002.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.003.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.004.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.005.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.006.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.007.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/2psfopcgmair2508.009.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm13070003.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm13070007.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm13070009.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070000.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070001.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070004.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070006.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070007.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070008.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/RNAPgm14070010.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/ferfchopg1308_002.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/ferfchopg_2910.026.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00001_16Bit.001_1024.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00005_16Bit.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00010_16Bit.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00029_16Bit.001_1024.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/glu0-26.0_00030_16Bit_1024.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapg1008.020.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.000.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.001.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.005.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.010.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.014.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.016.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.017.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.023.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.032.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.034.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.038.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/rnapstac0308.040.json  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_ferfchopg1308_002.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_ferfchopg_2910.026.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00001_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00010_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00030_16Bit_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00005_16Bit.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapg1008.020.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_glu0-26.0_00029_16Bit.001_1024.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm13070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm13070009.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm13070003.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070006.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070004.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070007.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.001.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.000.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_RNAPgm14070008.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.005.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.010.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.014.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.017.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.016.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.034.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.038.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.032.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.023.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_rnapstac0308.040.txt  \n",
            "  inflating: Splitted Dataset/Val/Masks/_2psfopcgmair2508.000.txt  \n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.6.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (11.3.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.7.0)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (1.0.24)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.10.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.25.0+cpu)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (4.67.3)\n",
            "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.12/dist-packages (from lightning) (6.0.3)\n",
            "Requirement already satisfied: fsspec<2028.0,>=2022.5.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2028.0,>=2022.5.0->lightning) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: packaging<27.0,>=23.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (26.0)\n",
            "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.12/dist-packages (from lightning) (4.15.0)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2028.0,>=2022.5.0->lightning) (3.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (0.24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2028.0,>=2022.5.0->lightning) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24->segmentation-models-pytorch) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (0.24.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.24->segmentation-models-pytorch) (0.1.2)\n",
            "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.6.1-py3-none-any.whl (853 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m853.6/853.6 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading pytorch_lightning-2.6.1-py3-none-any.whl (857 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.3/857.3 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning, segmentation-models-pytorch\n",
            "Successfully installed lightning-2.6.1 lightning-utilities-0.15.2 pytorch-lightning-2.6.1 segmentation-models-pytorch-0.5.0 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "#Example of working inference (any file from test dataset)\n",
        "from urllib.parse import urlencode\n",
        "import requests\n",
        "\n",
        "def get_yandex_link(url: str):\n",
        "  base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
        "  final_url = base_url + urlencode(dict(public_key=url))\n",
        "  response = requests.get(final_url)\n",
        "  download_url = response.json()['href']\n",
        "  return download_url\n",
        "\n",
        "weights_link = get_yandex_link(\"https://disk.yandex.ru/d/Ekz08ea7aiBBUA\") # Splitted data (train/val/test)\n",
        "!wget \"$weights_link\" -O weights.zip #make once per session\n",
        "!unzip weights.zip   #make once per session\n",
        "\n",
        "\n",
        "!wget https://ml.gan4x4.ru/msu/students/dubrovin/dataset.zip\n",
        "!unzip dataset.zip\n",
        "!pip install segmentation-models-pytorch lightning torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import nan\n",
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import warnings\n",
        "import ast\n",
        "#from torchvision import tv_tensors\n",
        "import pickle\n",
        "import torchvision.transforms.functional as F\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "def load_cache(filename = \"cachedm.pickle\"):\n",
        "      if os.path.isfile(filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "           cache =  pickle.load(f)\n",
        "        print(f\"Loaded cache from {filename}\")\n",
        "        return cache\n",
        "      return None\n",
        "cache = load_cache()\n",
        "\n",
        "class CustomDataset2chdm(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, target_transform = None, exclude = [], cache = None):\n",
        "      images = glob(f\"{root_dir}{os.sep}Images{os.sep}*\")\n",
        "      labels = glob(f\"{root_dir}{os.sep}Masks{os.sep}_*\") # read only continuous heigths\n",
        "      # extract id from paths\n",
        "      im = set(map(lambda x: Path(x).stem,images))\n",
        "      lab = set(map(lambda x: Path(x).stem[1:],labels))\n",
        "      img_without_masks = im - lab\n",
        "      if len(img_without_masks) > 0:\n",
        "        warn_text = f\"Found images without masks {','.join(img_without_masks)}\"\n",
        "        warnings.warn(warn_text)\n",
        "      self.items =  (list((im & lab) - set(exclude)))\n",
        "      self.items.sort()\n",
        "      self.root_dir = root_dir\n",
        "      self.transform = transform\n",
        "      self.target_transform = target_transform\n",
        "      self.max_height = 100\n",
        "      if cache == None:\n",
        "          self.cache = {}\n",
        "      else:\n",
        "        self.cache = cache\n",
        "\n",
        "      #self.load_cache()\n",
        "      #self.scales = self.get_all_scales()\n",
        "\n",
        "    def get_all_scales(self):\n",
        "        scales = []\n",
        "        for name in self.items:\n",
        "            path = self.get_im_path(name)\n",
        "            image, real_w = self.txt2pil(path)\n",
        "            scales.append(self.get_scale(image, real_w))\n",
        "        return np.array(scales)\n",
        "\n",
        "    def get_scale(self, img, real_w):\n",
        "      return  real_w / img.shape[1]   #  micron per pixel; \"[0]\" changed to \"[1]\"\n",
        "\n",
        "    def get_im_path(self,name):\n",
        "      path = f\"{self.root_dir}{os.sep}Images{os.sep}{name}.txt\"\n",
        "      return path\n",
        "\n",
        "    def get_mask_path(self,name):\n",
        "      path = f\"{self.root_dir}{os.sep}Masks{os.sep}_{name}.txt\"\n",
        "      return path\n",
        "\n",
        "    def save_cache(self,filename = \"cache.pickle\"):\n",
        "      with open(filename, 'wb') as f:\n",
        "        pickle.dump(self.cache, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def load_cache(self,filename = \"cache.pickle\"):\n",
        "      if os.path.isfile(filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "          self.cache =  pickle.load(f)\n",
        "        print(f\"Loaded cache from {filename}\")\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.items)\n",
        "\n",
        "    def line2tensor(self,line):\n",
        "        txt = line.strip()\n",
        "        parts = txt.split(\"\\t\")\n",
        "        parts = list(filter(len,parts)) #remove empty\n",
        "        if len(parts) <= 2:\n",
        "          return None\n",
        "        numbers = list(map(float, parts))\n",
        "        t = torch.tensor(numbers)\n",
        "        return t\n",
        "\n",
        "\n",
        "    def txt2pil(self, filename):\n",
        "      if filename in self.cache and \"image\" in self.cache[filename]:\n",
        "        return self.cache[filename][\"image\"].copy(), self.cache[filename][\"real_w\"]\n",
        "\n",
        "      # convert list of relative heights to image\n",
        "      with open(filename, encoding='unicode_escape') as file:\n",
        "        x_line = file.readline() # X\n",
        "        x = self.line2tensor(x_line[6:]) # bypass X,nm \"8:\" was replaced by \"5:\"\n",
        "        real_w = (x.max()-x.min()).item() #let it be in microns\n",
        "        units = x_line[3:5]\n",
        "        if units == \"A°\":\n",
        "          real_w = real_w/10000\n",
        "        if units == \"nm\":\n",
        "          real_w = real_w/1000\n",
        "        line = file.readline() # Y, Z skip it\n",
        "        lines = []\n",
        "        for line in file:\n",
        "          if line != '\\n':  #to exclude the last line\n",
        "            pos = line.index('\\t')#position of the first tabulation\n",
        "            line2 = line[(pos + 2):]#exclude Y-coordinate and 2 tabulations after it\n",
        "            t = self.line2tensor(line2)\n",
        "            if t is not None:\n",
        "              lines.append(t)\n",
        "        t = torch.stack(lines)\n",
        "        # Shift to zero\n",
        "        # Because all heights just a difference between current and randomly sampled point\n",
        "        t = t - t.min()\n",
        "        t = t.numpy()\n",
        "        self.cache[filename]= {\"image\": t, \"real_w\" : real_w}\n",
        "      return t, real_w\n",
        "\n",
        "\n",
        "    def load_heights(self, path):\n",
        "      \"\"\"\n",
        "        get heights of some points marked by human\n",
        "      \"\"\"\n",
        "      df = pd.read_excel(path)\n",
        "      return self.fix_format(df)\n",
        "\n",
        "\n",
        "    def get_height_map(self, path):\n",
        "      if not (path in self.cache and \"mask\" in self.cache[path]):\n",
        "          with open(path, 'r') as file:\n",
        "            content = file.read()\n",
        "          x = ast.literal_eval(content)\n",
        "          x = np.array(x)\n",
        "          self.cache[path] = { \"mask\" : x }\n",
        "      return self.cache[path][\"mask\"].copy()\n",
        "      #return x\n",
        "\n",
        "\n",
        "    def __getitem__(self,n):\n",
        "      \"\"\"\n",
        "        img - data(raw heights) from microscope\n",
        "        masks - continious globules height map\n",
        "\n",
        "        real_w - width of the image in microns\n",
        "      \"\"\"\n",
        "      name = self.items[n]\n",
        "      img = self.get_im_path(name)\n",
        "      mask = self.get_mask_path(name)\n",
        "\n",
        "      image, real_w = self.txt2pil(img)\n",
        "      mask = self.get_height_map(mask)\n",
        "\n",
        "      #image, orig_size, scale_factor = self.rescale(image,real_w)\n",
        "      #mask, _, _ = self.rescale(mask,real_w)\n",
        "      scale_factor = 0\n",
        "\n",
        "      if self.transform:\n",
        "        output = self.transform(image=image, mask=mask)\n",
        "        image = output['image']\n",
        "        mask = output['mask'] # here mask is cropped but not normalized\n",
        "        if self.target_transform:\n",
        "          mask = self.target_transform(mask)\n",
        "      meta = {\"w\": real_w, 'name' : name, \"scale_factor\": scale_factor}\n",
        "      binary_mask = torch.where(mask != 0, 1, 0)\n",
        "      mask2 = torch.unsqueeze(binary_mask, 0)\n",
        "      im_mask = torch.cat((image, mask2), 0) #creates two channel tensor, where 1 channel is image, 2nd channel is mask\n",
        "      return im_mask, image, mask, meta\n",
        "\n",
        "    def rescale(self,img, real_w):\n",
        "      resize_coeff = 1\n",
        "      h,w = img.shape[:2]\n",
        "      original_size = (h,w)\n",
        "      #most_popular_scale = mode(self.scales)\n",
        "      most_popular_scale = 0.00389862060546875\n",
        "      scale = self.get_scale(img,real_w)\n",
        "      if most_popular_scale != scale:\n",
        "        resize_coeff = most_popular_scale/scale\n",
        "      new_size = tuple((np.array(original_size) / resize_coeff).astype(int).tolist()) # '*' changed to '/'\n",
        "      img = cv2.resize(img, new_size)\n",
        "      return img, original_size, resize_coeff"
      ],
      "metadata": {
        "id": "je33EylelYP7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "metadata": {
        "id": "vTTJMMtwlbLk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean, std = [8.489298], [9.06547]\n",
        "\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean, std),\n",
        "        A.RandomCrop(192, 192),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = A.Compose(\n",
        "    [\n",
        "        A.Normalize(mean, std),\n",
        "        A.CenterCrop(192, 192),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "class NormalizeNonZero(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, x):\n",
        "        mask = x == 0\n",
        "        x -= self.mean\n",
        "        x /= self.std\n",
        "        x[mask] = 0\n",
        "        return x.to(torch.float32)\n",
        "\n",
        "    def denorm(self,x):\n",
        "        mask = x == 0\n",
        "        x *=  self.std\n",
        "        x += self.mean\n",
        "        x[mask] = 0\n",
        "        return x\n",
        "\n",
        "dot_target_mean, dot_target_std = 3.016509424749255, 2.452459479074767\n",
        "nnz = NormalizeNonZero(dot_target_mean, dot_target_std)\n",
        "\n",
        "target_transform = T.Compose([nnz])"
      ],
      "metadata": {
        "id": "jxmy2qxNllBM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2\n",
        "\n",
        "from math import nan\n",
        "from torch.utils.data import Dataset\n",
        "from glob import glob\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "import warnings\n",
        "import ast\n",
        "#from torchvision import tv_tensors\n",
        "import pickle\n",
        "import torchvision.transforms.functional as F\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "vKxpyqYLlnK7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ds_train = CustomDataset2chdm(\"Splitted Dataset/Train\", transform  = train_transforms, target_transform = target_transform, cache = cache)\n",
        "loader_train = DataLoader(ds_train, batch_size=16, shuffle=True, num_workers=2)\n",
        "#ds_train = CustomDataset(\"Splitted Dataset/Train\")\n",
        "\n",
        "ds_val = CustomDataset2chdm(\"Splitted Dataset/Val\", transform  = val_transforms, target_transform=target_transform, cache = cache)\n",
        "loader_val = DataLoader(ds_val, batch_size=4, shuffle=False, num_workers=2)\n",
        "#ds_val = CustomDataset(\"Splitted Dataset/Val\")\n",
        "'''\n",
        "\n",
        "ds_test = CustomDataset2chdm(\"Splitted Dataset/Test\", transform  = val_transforms, target_transform=target_transform, cache = cache)\n",
        "loader_test = DataLoader(ds_test, batch_size=4, shuffle=False, num_workers=2)\n",
        "#ds_test = CustomDataset(\"Splitted Dataset/Test\")"
      ],
      "metadata": {
        "id": "Tu6dh7I-plex"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import MeanSquaredError\n",
        "from typing import Any, Optional, Sequence, Union\n",
        "from torch import Tensor\n",
        "\n",
        "class ZeroAwareMSE(MeanSquaredError):\n",
        "    def update(self, preds: Tensor, target: Tensor) -> None:\n",
        "        target_sum = torch.sum(target).item()\n",
        "        if target_sum == 0:#change preds and targets in such a way that the result would be zero tensor (not works directly)\n",
        "            preds = preds - preds + 1\n",
        "            target = target + 1\n",
        "        mask = target != 0\n",
        "        return super().update(preds[mask],target[mask])\n"
      ],
      "metadata": {
        "id": "67bQWP-Rlq3r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MSELoss_mask(pred, target): #MSE loss calculated only inside the masks (which are contained in the targets)\n",
        "  mse_loss = MSELoss(reduction='sum')  #calculates sum of the squared errors (without division by n)\n",
        "  loss = mse_loss(pred, target) #calculates sum of the squared errors (without division by n)\n",
        "  target_binary = torch.where(target != 0, 1, 0) #writing 1 in each unmasked pixel and 0 in each masked pixel (for calculation the number of unmasked pixels)\n",
        "  n_ummasked_pxls = target_binary.sum()#.item() #calculating the number of unmasked pixels\n",
        "  if n_ummasked_pxls == 0:\n",
        "    return 0\n",
        "\n",
        "  return loss/n_ummasked_pxls\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class CustomLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomLoss, self).__init__()\n",
        "\n",
        "  def forward(self, pred, target):\n",
        "    return MSELoss_mask(pred, target)"
      ],
      "metadata": {
        "id": "ML01J5fFlrWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightning as L\n",
        "from torchmetrics import MeanSquaredError\n",
        "from torch.nn import MSELoss\n",
        "import torch\n",
        "\n",
        "class Lit(L.LightningModule):\n",
        "    def __init__(self, model, lr=0.0025):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "        self.criterion = CustomLoss()\n",
        "        self.save_hyperparameters()\n",
        "        self.metric_train = ZeroAwareMSE()\n",
        "        self.metric_train_dn = ZeroAwareMSE()\n",
        "        self.metric_val = ZeroAwareMSE()\n",
        "        self.metric_val_dn = ZeroAwareMSE()\n",
        "        self.metric_test = ZeroAwareMSE()\n",
        "        self.metric_test_dn = ZeroAwareMSE()  #??\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        _, imgs, masks, meta = batch\n",
        "        predicted_masks = self.get_prediction(batch)\n",
        "        #print(predicted_masks, masks)\n",
        "        loss = self.criterion(predicted_masks, masks)\n",
        "        #loss_dn = self.criterion(nnz.denorm(predicted_masks), nnz.denorm(masks))\n",
        "        self.log(\"Loss/\", loss.item(), prog_bar=False)\n",
        "        #self.log(\"Loss_dn/\", loss_dn.item(), prog_bar=False)\n",
        "        self.metric_train.update(predicted_masks, masks)\n",
        "        #self.metric_train_dn.update(nnz.denorm(predicted_masks), nnz.denorm(masks))\n",
        "        return loss\n",
        "\n",
        "    def get_prediction(self,batch):\n",
        "        im_masks, imgs, masks, meta = batch\n",
        "        predicted_masks = self.model(im_masks).squeeze(1)\n",
        "        predicted_masks = self.postprocess(predicted_masks, masks)\n",
        "        return predicted_masks\n",
        "\n",
        "    def postprocess(self, pred, mask):\n",
        "        pred = pred.squeeze(1)\n",
        "        pred[mask == 0] = 0\n",
        "        return pred\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, imgs, masks, meta = batch\n",
        "        predicted_masks = self.get_prediction(batch)\n",
        "        self.metric_val.update(predicted_masks, masks)\n",
        "        self.metric_val_dn.update(nnz.denorm(predicted_masks), nnz.denorm(masks))\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        self.log(\"MSE/val\", self.metric_val.compute(), prog_bar=True)\n",
        "        self.log(\"MSE/val_dn\", self.metric_val_dn.compute(), prog_bar=True)\n",
        "        self.metric_val.reset()\n",
        "        self.metric_val_dn.reset()\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.log(\"MSE/train\", self.metric_train.compute())\n",
        "        #self.log(\"MSE_dn/train\", self.metric_train_dn.compute())\n",
        "        self.metric_train.reset()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        im_masks, imgs, masks, _ = batch\n",
        "        predicted_masks = self.get_prediction(batch)\n",
        "        self.log(\"MSE/test\", self.metric_test.compute(), prog_bar=True)\n",
        "        self.metric_test.update(predicted_masks, masks)\n",
        "        self.metric_test_dn.update(nnz.denorm(predicted_masks), nnz.denorm(masks))#??\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log(\"MSE/test\", self.metric_test.compute(), prog_bar=True)\n",
        "        self.log(\"MSE/test_dn\", self.metric_test_dn.compute(), prog_bar=True)\n",
        "        self.metric_test.reset()\n",
        "        self.metric_test_dn.reset()"
      ],
      "metadata": {
        "id": "w2ivf6U_lwIT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "smp_unet = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b0\",  # choose encoder\n",
        "    encoder_weights=None,  # use `imagenet` pre-trained weights for encoder initialization\n",
        "    in_channels=2,  # model input channels 3 for RGB\n",
        "    classes=1,  # model output channels (number of classes in mask)\n",
        ")"
      ],
      "metadata": {
        "id": "gQGnHolflzfr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='MSE/val',\n",
        "    #monitor='MSE/train',\n",
        "    dirpath='lightning_logs',\n",
        "    #filename='sample-mnist-{epoch:02d}-{val_loss:.2f}',\n",
        "    save_top_k=5,\n",
        "    mode='min',\n",
        "    #every_n_epochs=10\n",
        ")\n",
        "\n",
        "lit_model = Lit(smp_unet)\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name=\"SMPUnet\")\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=1,\n",
        "    logger=logger,\n",
        "    log_every_n_steps=5,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")  # def on_validation_epoch_start(self):\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBoOEfP5pzK5",
        "outputId": "7f0caf64-a119-4706-8668-f2efc3bd24c9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/parsing.py:213: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: 💡 Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:💡 Tip: For seamless cloud logging and experiment tracking, try installing [litlogger](https://pypi.org/project/litlogger/) to enable LitLogger, which logs metrics and artifacts automatically to the Lightning Experiments platform.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lit_model1 = Lit.load_from_checkpoint('Weights/epoch=4993-step=59928.ckpt', weights_only=False)\n",
        "model = lit_model1.model\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "_81mBlxTl1Or",
        "outputId": "774a06d4-043f-4544-d446-dbe0472537c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL segmentation_models_pytorch.decoders.unet.model.Unet was not an allowed global by default. Please use `torch.serialization.add_safe_globals([segmentation_models_pytorch.decoders.unet.model.Unet])` or the `torch.serialization.safe_globals([segmentation_models_pytorch.decoders.unet.model.Unet])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1734078012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlit_model1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Weights/epoch=4993-step=59928.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlit_model1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/utilities/model_helpers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;34m\" Please call it on the class type and make sure the return value is used.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 )\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, weights_only, **kwargs)\u001b[0m\n\u001b[1;32m   1795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \"\"\"\n\u001b[0;32m-> 1797\u001b[0;31m         loaded = _load_from_checkpoint(\n\u001b[0m\u001b[1;32m   1798\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/pytorch/core/saving.py\u001b[0m in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, weights_only, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpl_legacy_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# convert legacy checkpoints to the new format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/lightning/fabric/utilities/cloud_io.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         return torch.load(\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1546\u001b[0m                         )\n\u001b[1;32m   1547\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1549\u001b[0m                 return _load(\n\u001b[1;32m   1550\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL segmentation_models_pytorch.decoders.unet.model.Unet was not an allowed global by default. Please use `torch.serialization.add_safe_globals([segmentation_models_pytorch.decoders.unet.model.Unet])` or the `torch.serialization.safe_globals([segmentation_models_pytorch.decoders.unet.model.Unet])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "def get_dotted_cropped_test_mask(flnm):\n",
        "    root_dir = \"Splitted Dataset/Test\"\n",
        "    path = f\"{root_dir}{os.sep}Masks{os.sep}_{flnm}.txt\"\n",
        "    with open(path, 'r') as file:\n",
        "        content = file.read()\n",
        "        x = ast.literal_eval(content)\n",
        "        x = np.array(x)\n",
        "    return x\n",
        "\n",
        "def get_dotted_cropped_val_mask(flnm):\n",
        "    root_dir = \"Splitted Dataset/Val\"\n",
        "    path = f\"{root_dir}{os.sep}Masks{os.sep}_{flnm}.txt\"\n",
        "    with open(path, 'r') as file:\n",
        "        content = file.read()\n",
        "        x = ast.literal_eval(content)\n",
        "        x = np.array(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_-JfpgLumOPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "dot_mse = []\n",
        "for item in ds_test:\n",
        "    im_mask, img, mask, meta = item\n",
        "    pred = model(im_mask.unsqueeze(0))\n",
        "    d_pred = nnz.denorm(pred)\n",
        "    d_pred = d_pred.squeeze(0).squeeze(0)\n",
        "    d_pred[mask ==0] =0\n",
        "    d_mask = nnz.denorm(mask)\n",
        "    flnm = meta['name']\n",
        "    dotted_mask = get_dotted_cropped_test_mask(flnm)\n",
        "    t = torch.from_numpy(dotted_mask)\n",
        "    center_crop = [A.CenterCrop(192, 192)(image = t)]\n",
        "    ten_cr = center_crop[0]['image']\n",
        "    zmse = ZeroAwareMSE()\n",
        "    dot_mse.append(zmse(d_pred,ten_cr).item())\n",
        "print(\"Mean dotted MSE on test =\", np.mean(dot_mse))\n",
        "'''"
      ],
      "metadata": {
        "id": "huZp2g3OmQZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_masks, img, mask, meta = ds_test[1]  #Designate here the image for inference\n",
        "pred = model(im_masks.unsqueeze(0))\n",
        "d_pred = nnz.denorm(pred)\n",
        "d_pred = d_pred.squeeze(0).squeeze(0)\n",
        "d_pred[mask ==0] =0\n",
        "d_mask = nnz.denorm(mask)"
      ],
      "metadata": {
        "id": "jr5FvqOssofh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(9,3))\n",
        "ttt1 = img.squeeze(0).detach().cpu().numpy()\n",
        "plt.subplot(1,4,1)\n",
        "plt.title('Initial image')\n",
        "ttt1 = plt.imshow(ttt1)\n",
        "\n",
        "ttt2 = d_mask.squeeze(0).detach().cpu().numpy()\n",
        "plt.subplot(1,4,2)\n",
        "plt.title('Target')\n",
        "ttt2 = plt.imshow(ttt2)\n",
        "\n",
        "\n",
        "ttt3 = d_pred.squeeze(0).detach().cpu().numpy()\n",
        "plt.subplot(1,4,3)\n",
        "plt.title('Model prediction')\n",
        "ttt3 = plt.imshow(ttt3)"
      ],
      "metadata": {
        "id": "xdkQnrdotIzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flnm = meta['name']\n",
        "dotted_mask = get_dotted_cropped_test_mask(flnm)\n",
        "t = torch.from_numpy(dotted_mask)\n",
        "center_crop = [A.CenterCrop(192, 192)(image = t)]\n",
        "ten_cr = center_crop[0]['image']\n",
        "zmse = ZeroAwareMSE()\n",
        "aaaa=zmse(d_pred,ten_cr)\n",
        "print('MSE = ', aaaa.item())"
      ],
      "metadata": {
        "id": "FiHSEsL3tLWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}